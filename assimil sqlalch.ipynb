{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e23f6d74-4822-4f72-99ff-2799ff992e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from sqlalchemy import create_engine, insert, select\n",
    "\n",
    "from lesson_parser import MyHTMLParser, get_words\n",
    "\n",
    "lessons_directory = f\"Sentences\"\n",
    "\n",
    "db_directory = \"./\"\n",
    "word_dict_filename = \"test_tonic_accent_word_dict.db\"\n",
    "\n",
    "def get_html_lesson_list():\n",
    "    file_list = []\n",
    "    m = \"L[\\d]{3}\"\n",
    "    p = re.compile(m)\n",
    "    w = os.walk(\"Sentences/html\")\n",
    "    for (dirpath, dirnames, filenames) in w:\n",
    "        for fn in filenames:\n",
    "            if p.match(fn):\n",
    "                file_list.append(fn)\n",
    "    return sorted(file_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c51cffd-a5f5-49f9-9f1f-b448d63f0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = get_html_lesson_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96fcff7e-227b-40de-9ddf-0f28aa042a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_word_dict_from_html_files(filenames, word_dict):\n",
    "    for fn in filenames:\n",
    "        print(fn)\n",
    "        lesson = open(os.path.join(lessons_directory, \"html\", fn)).read()\n",
    "        print(fn, \" : \", len(lesson))\n",
    "        parser.analyze_lesson(lesson)\n",
    "        wd = parser.get_lesson_word_dict()\n",
    "        for w in wd:\n",
    "            if not w in word_dict:\n",
    "                word_dict[w] = wd[w]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ed53170-577f-411e-a265-4127a510f815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L001.html\n",
      "L001.html  :  1428\n",
      "L002.html\n",
      "L002.html  :  631\n",
      "L003.html\n",
      "L003.html  :  2141\n",
      "L004.html\n",
      "L004.html  :  670\n",
      "L005.html\n",
      "L005.html  :  812\n",
      "L006.html\n",
      "L006.html  :  785\n",
      "L007.html\n",
      "L007.html  :  751\n",
      "L008.html\n",
      "L008.html  :  1117\n",
      "L009.html\n",
      "L009.html  :  1059\n",
      "L010.html\n",
      "L010.html  :  1064\n",
      "L011.html\n",
      "L011.html  :  1216\n",
      "L012.html\n",
      "L012.html  :  1104\n",
      "L013.html\n",
      "L013.html  :  1187\n",
      "L014.html\n",
      "L014.html  :  954\n",
      "L015.html\n",
      "L015.html  :  1058\n",
      "L016.html\n",
      "L016.html  :  1392\n",
      "L017.html\n",
      "L017.html  :  1143\n",
      "L018.html\n",
      "L018.html  :  1307\n",
      "L019.html\n",
      "L019.html  :  1206\n",
      "L020.html\n",
      "L020.html  :  1273\n",
      "L021.html\n",
      "L021.html  :  1276\n",
      "L022.html\n",
      "L022.html  :  1353\n",
      "L023.html\n",
      "L023.html  :  1490\n",
      "L024.html\n",
      "L024.html  :  1367\n",
      "L025.html\n",
      "L025.html  :  1642\n",
      "L026.html\n",
      "L026.html  :  1471\n",
      "L027.html\n",
      "L027.html  :  1544\n",
      "L028.html\n",
      "L028.html  :  1317\n",
      "L029.html\n",
      "L029.html  :  1871\n",
      "L030.html\n",
      "L030.html  :  1683\n",
      "L031.html\n",
      "L031.html  :  1671\n",
      "L032.html\n",
      "L032.html  :  1715\n",
      "L033.html\n",
      "L033.html  :  2007\n",
      "L034.html\n",
      "L034.html  :  1561\n",
      "L035.html\n",
      "L035.html  :  1448\n",
      "L036.html\n",
      "L036.html  :  1768\n",
      "L037.html\n",
      "L037.html  :  1885\n",
      "L038.html\n",
      "L038.html  :  1846\n",
      "L039.html\n",
      "L039.html  :  1632\n",
      "L040.html\n",
      "L040.html  :  1607\n",
      "L041.html\n",
      "L041.html  :  1743\n",
      "L042.html\n",
      "L042.html  :  1678\n",
      "L043.html\n",
      "L043.html  :  1853\n",
      "L044.html\n",
      "L044.html  :  1809\n",
      "L045.html\n",
      "L045.html  :  1624\n",
      "L046.html\n",
      "L046.html  :  1831\n",
      "L047.html\n",
      "L047.html  :  1823\n",
      "L048.html\n",
      "L048.html  :  1703\n",
      "L049.html\n",
      "L049.html  :  1624\n",
      "L050.html\n",
      "L050.html  :  1984\n",
      "L051.html\n",
      "L051.html  :  2104\n",
      "L052.html\n",
      "L052.html  :  1866\n",
      "L053.html\n",
      "L053.html  :  2046\n",
      "L054.html\n",
      "L054.html  :  2149\n",
      "L055.html\n",
      "L055.html  :  2039\n",
      "L056.html\n",
      "L056.html  :  1643\n",
      "L057.html\n",
      "L057.html  :  2165\n",
      "L058.html\n",
      "L058.html  :  2349\n",
      "L059.html\n",
      "L059.html  :  2333\n",
      "L060.html\n",
      "L060.html  :  2265\n",
      "L061.html\n",
      "L061.html  :  2512\n",
      "L062.html\n",
      "L062.html  :  2295\n",
      "L063.html\n",
      "L063.html  :  1768\n",
      "L064.html\n",
      "L064.html  :  2012\n",
      "L065.html\n",
      "L065.html  :  2269\n",
      "L066.html\n",
      "L066.html  :  2358\n",
      "L067.html\n",
      "L067.html  :  2227\n",
      "L068.html\n",
      "L068.html  :  2499\n",
      "L069.html\n",
      "L069.html  :  2458\n",
      "L070.html\n",
      "L070.html  :  1728\n",
      "L071.html\n",
      "L071.html  :  2129\n",
      "L072.html\n",
      "L072.html  :  2429\n",
      "L073.html\n",
      "L073.html  :  2281\n",
      "L074.html\n",
      "L074.html  :  2331\n",
      "L075.html\n",
      "L075.html  :  2196\n",
      "L076.html\n",
      "L076.html  :  2310\n",
      "L077.html\n",
      "L077.html  :  1808\n",
      "L078.html\n",
      "L078.html  :  2383\n",
      "L079.html\n",
      "L079.html  :  2329\n"
     ]
    }
   ],
   "source": [
    "word_dict = {}\n",
    "parser = MyHTMLParser()\n",
    "fill_word_dict_from_html_files(file_list, word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34f3df8d-fd6f-4d3e-8ca5-258407810a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keys : 2600\n"
     ]
    }
   ],
   "source": [
    "keys_number = 0\n",
    "for key in word_dict:\n",
    "    keys_number += 1\n",
    "print(f\"Number of keys : {keys_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8501867-527f-4690-8c47-b30c5d865549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing import Optional\n",
    "from sqlalchemy.orm import Mapped\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "from sqlalchemy.orm import DeclarativeBase\n",
    "\n",
    "class Base(DeclarativeBase):\n",
    "    pass\n",
    "\n",
    "class WordDict(Base):\n",
    "    __tablename__ = \"word_dict\"\n",
    "    id: Mapped[int] = mapped_column(primary_key=True)\n",
    "    word: Mapped[str] \n",
    "    word_struct: Mapped[str]\n",
    "    comment: Mapped[Optional[str]]\n",
    "    index: Mapped[str]\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"WordDict(id={self.id!r}, word={self.word!r}, comment={self.comment!r})\"\n",
    "\n",
    "class Sentence(Base):\n",
    "    __tablename__ = \"sentences\"\n",
    "    id: Mapped[int] = mapped_column(primary_key=True)\n",
    "    sentence: Mapped[str] \n",
    "    comment: Mapped[Optional[str]]\n",
    "    lesson : Mapped[int]\n",
    "    line : Mapped[int]\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Sentence(id={self.id!r}, word={self.sentence!r}, lesson={lesson!r}, numero={numero!r}, comment={self.comment!r})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c906aae3-3f7d-45d6-b5ca-90e8c514ba2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sqlite:///test_tonic_accent_word_dict.db'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_name = Path(db_directory, word_dict_filename)\n",
    "db_url  = f\"sqlite:///{db_name}\"\n",
    "db_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06cb4321-ea42-4e15-a2dc-e5e08d6252e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "engine = create_engine(db_url, echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba409a4c-face-4fff-a2aa-360b51f31b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = Base.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baedd3c5-abbc-4403-b294-79dab7f7d512",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95b028d4-0738-4a2f-9e4e-77feba3cb3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_table = metadata.tables['word_dict']\n",
    "sentence_table = metadata.tables['sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44a12c8a-2c0f-414f-9932-d77e68bff42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(lesson_nb : int):\n",
    "    lesson_filename = f\"Sentences/html/L{str(lesson_nb).zfill(3)}.html\"\n",
    "    try:\n",
    "        f = open(lesson_filename, \"r\")\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "        lesson = \"\"\n",
    "        for line in lines:\n",
    "            lesson += line\n",
    "        parser.analyze_lesson(lesson)\n",
    "        sentences = parser.get_sentences()\n",
    "    except FileNotFoundError:\n",
    "        sentences = get_sentences_from_audio_files(lesson_nb)\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b041002a-84c2-4d97-a946-2ada2d24b11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S01',\n",
       " 'Felipe',\n",
       " 'guapo',\n",
       " 'dame',\n",
       " 'diez',\n",
       " 'lonchas',\n",
       " 'de',\n",
       " 'jamón',\n",
       " 'de',\n",
       " 'york',\n",
       " 'por',\n",
       " 'favor']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = get_sentences(50)\n",
    "get_words(sentences[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259a8b60-6160-4704-b043-fcabf15d7324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_word_dict_table(filenames, word_dict):\n",
    "    for fn in filenames:\n",
    "        print(fn)\n",
    "        lesson = open(os.path.join(lessons_directory, \"html\", fn)).read()\n",
    "        print(fn, \" : \", len(lesson))\n",
    "        parser.analyze_lesson(lesson)\n",
    "        sentences = parser.get_sentences()\n",
    "        for sentence in sentences:\n",
    "            words = get_words(sentence)\n",
    "            for w in words:\n",
    "                if w in word_dict:\n",
    "                    stmt =\n",
    "                else:\n",
    "                    index = [\n",
    "                    stmt = insert(word_table).values(word=word, word_struct=pickle.dumps(word_dict[word]))\n",
    "            \n",
    "        for w in wd:\n",
    "            if not w in word_dict:\n",
    "                word_dict[w] = wd[w]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c7a7f1-1a64-4a60-a10c-2fe55459678d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd26b9fc-07da-4e13-9a5b-90ba0d4b60b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24673375-b669-4c39-b78c-eae2ec8ec9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93808c6-8a37-46d4-ad61-a0fc883b36c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73426ce2-a8ad-4f4c-9b2d-0d97939399a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6875e1b-3251-4e77-9e03-b769592f206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    for word in word_dict:\n",
    "        stmt = insert(word_table).values(word=word, word_struct=pickle.dumps(word_dict[word]))\n",
    "        result = conn.execute(stmt)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d1e48c3-0a0e-42b3-b139-23b2317b4384",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = select(word_table).where(word_table.c.word == \"acontecimiento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa718e3e-83e0-4b68-a3df-90145a3fc5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word : acontecimiento, structure : [('aconteci', False), ('mien', True), ('to', False)]\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    for row in conn.execute(stmt):\n",
    "        print(f\"word : {row.word}, structure : {pickle.loads(row.word_struct)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6b78c0e-3db5-45eb-8d92-a7694e8c6633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word : traduzca, structure : [('Tra', False), ('du', True), ('zca', False)]\n"
     ]
    }
   ],
   "source": [
    "stmt = select(word_table).where(word_table.c.word == \"traduzca\")\n",
    "with engine.connect() as conn:\n",
    "    for row in conn.execute(stmt):\n",
    "        print(f\"word : {row.word}, structure : {pickle.loads(row.word_struct)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22fd701e-d68e-4575-bcc0-ce5f17a16bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word : y, structure : [('Y', False)]\n"
     ]
    }
   ],
   "source": [
    "stmt = select(word_table).where(word_table.c.word == \"y\")\n",
    "with engine.connect() as conn:\n",
    "    for row in conn.execute(stmt):\n",
    "        print(f\"word : {row.word}, structure : {pickle.loads(row.word_struct)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8eae2439-d121-4bfa-a3e8-bdd1d84526be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    for k in range(79):\n",
    "        lesson = k + 1\n",
    "        sentences = get_sentences(lesson)\n",
    "        for line in range(len(sentences)):\n",
    "            stmt = insert(sentence_table).values(sentence=sentences[line], lesson=lesson, line=line)\n",
    "            conn.execute(stmt)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30c3e730-e803-4567-b104-70934399e0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line : 0, sentence : N72-Lección setenta y dos\n",
      "line : 1, sentence : S00-TITLE-Ya que estoy\n",
      "line : 2, sentence : S01-Mírese en el espejo, ¿cómo se siente? \n",
      "line : 3, sentence : S02-Así así\n",
      "line : 4, sentence : S03-Es una prenda de entretiempo, de algodón. Le serviría tanto para primavera como para otoño. \n",
      "line : 5, sentence : S04-Me queda un poco estrecho de cintura, ¿no? \n",
      "line : 6, sentence : S05-A ver, muévase un poco, dese la vuelta. Perdiendo un kilito, le quedaría perfecto. \n",
      "line : 7, sentence : S06-Tengo que ponerme a dieta, tiene toda la razón. \n",
      "line : 8, sentence : S07-Es de rayas ¿Cree que me favorece? \n",
      "line : 9, sentence : S08-Le queda fabuloso, pero existe también liso y de cuadros. Yo que usted me llevaría los tres. \n",
      "line : 10, sentence : S09-Venga, un día es un día. Ah, ya que estoy, he visto que tiene sección de caballeros. \n",
      "line : 11, sentence : S10-Mi marido va siempre de traje, pero me gustaría algo más informal. Una americana sport, talla 50. \n",
      "line : 12, sentence : S11-¡Esta, con su corbata a juego! Encima está rebajada, y si lo necesita hacemos arreglos. \n",
      "line : 13, sentence : S12-¿Algo más, señora, algún detallito para su cuñada? \n",
      "line : 14, sentence : S13-Buena idea, deme esa blusa morada. Odia ese color. \n",
      "line : 15, sentence : S14-¿Qué talla usa? \n",
      "line : 16, sentence : S15-Una 40, pero búsqueme una 38\n",
      "line : 17, sentence : T00-TRANSLATE-Ejercicio 1 – Traduzca\n",
      "line : 18, sentence : T01-Esta americana de entretiempo le serviría para este otoño. \n",
      "line : 19, sentence : T02-Dese la vuelta delante del espejo ¿a que le queda bien? \n",
      "line : 20, sentence : T03-Ya que estoy, quisiera un traje de algodón, de rayas y con una corbata a juego. \n",
      "line : 21, sentence : T04-Esta prenda me queda perfecta, pero me gustaría algo más informal. \n",
      "line : 22, sentence : T05-Uso una 42, pero a veces una 40 me queda bastante bien. \n"
     ]
    }
   ],
   "source": [
    "stmt = select(sentence_table).where(sentence_table.c.lesson == 72)\n",
    "with engine.connect() as conn:\n",
    "    for row in conn.execute(stmt):\n",
    "        print(f\"line : {row.line}, sentence : {row.sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2064804-45cf-4943-bd4f-09cb4d89d86d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
